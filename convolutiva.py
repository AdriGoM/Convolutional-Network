# -*- coding: utf-8 -*-
"""Convolutiva.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Se4ql10RzGGiPeUQEdery7bxBpcGMK9L

# Distinguir entre perros y gatos

Vamos a desarrollar una red que clasifique imágenes en función de si es un perro o un gato. Para ello, vamos a utilizar un dataset contenido en nuestra cuenta de Google Drive. Antes, debemos montar nuestro sistema de archivos de Google Drive para hacerlo accesible desde este *notebook*. Google nos solicitará permiso, tenemos que copiar y pegar el código que nos suministra.
"""

from google.colab import drive
drive.mount('/content/drive')

"""Ahora ya es accesible"""



"""¿Estoy realmente utilizando una GPU? Compruébalo en **Editar / Configuración del cuaderno** o **Entorno de ejecuación / Cambiar tipo de entorno de ejecución**"""

!ls "/content/drive/My Drive/Colab_Notebooks/datasets/dogs_and_cats/train/dogs/"

from matplotlib.pyplot import imshow #Libreria para la visualización gráfica
import numpy as np 
from PIL import Image 

# %matplotlib inline 
pil_im = Image.open('/content/drive/My Drive/Colab_Notebooks/datasets/dogs_and_cats/train/dogs/dog.998.jpg', 'r')
imshow(np.asarray(pil_im))

import tensorflow as tf
tf.test.gpu_device_name()

"""## Modelo
Modelo convolutivo con 3 capas convolutivas. El kernel empleado es de 3 x 3 en todos los casos. En cada una de las capas, se emplean 32, 64 y 128 filtros. Posteriormente almacenamos todos los datos extraidos de las características de cada imagen en un vector unidimensional. Esto nos será de utilidad para con ese conjunto de datos, pasarlo por las capas intermedias. En este caso utilizo 3 capas densas. En las 2 primeras aplicamos capas de 64 y 128 neuronas que se encargarán de mejorar la clasificación de las caracteristicas anteriores. Por útlimo, usamos una capa de salida de unicamente 2 neuronas que nos permitirá saber si ese conjunto de datos corresponde a un perro o a un gato.
"""

from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
import keras
from time import time


# DATA SOURCE --------------------------------------------------

batch_size = 20 # Número de datos que coges en cada paso de entrenamiento

train_data_dir = '/content/drive/My Drive/Colab_Notebooks/datasets/dogs_and_cats/train'
validation_data_dir = '/content/drive/My Drive/Colab_Notebooks/datasets/dogs_and_cats/validation'


#Entre + imágenes mejor
#Flip horizontal para obtener el doble de imágenes(voltado)
#Podemos hacer un zoom
#Podemos rotar la imagen 
#Keras hace esa funcion por nosotros mediante el metodo ImageDataGenerator
train_datagen = ImageDataGenerator(
        rescale=1./255, # No confundir con el zoom. 1 pixel 3 bytes. 
                        # Cada byte 0-255. Multplica cada valor por 1/255
                        # para normalizar el dato y dejarlo entre 0 y 1
        shear_range=0.2, # 0 - 20 grados
        zoom_range=0.2, # Zoom
        horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory( #Tomamos las imagenes
        train_data_dir,
        target_size=(150, 150), #Tamaño fijo para la red 
        batch_size=batch_size, 
        class_mode='categorical') # Binario(1 neurona 1 o 0) o 
                                  # categórico (red clasifica en 3 o más clases)


validation_generator = test_datagen.flow_from_directory(
      validation_data_dir,
        target_size=(150, 150),
       batch_size=32,
        class_mode='categorical')

# MODEL --------------------------------------------------
# 3 Bytes de ancho por ser a color y tener 3 canales rgb 
model = Sequential() # Capas secuenciales 

model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=(150, 150, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))


model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())

model.add(Dense(64, activation='relu'))
model.add(Dropout(0.33))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.33))
model.add(Dense(2, activation='softmax'))


model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
# loss --> Función de pérdida MSE
# optimizer --> adadelta no importa detalle
# metrics --> Medidas para ver la evolución del entrenamiento de la red 

# TRAINING --------------------------------------------------

epochs = 10


history = model.fit_generator( 
        train_generator,
        steps_per_epoch=100,
        epochs=epochs, 
        validation_data=validation_generator,
        validation_steps=300,
)

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()